{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AMV7f-xdtDkF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = \"/content/ecopackai/ml\"\n",
        "\n",
        "EXPERIMENTS_DIR = f\"{BASE}/experiments\"\n",
        "METADATA_DIR = f\"{EXPERIMENTS_DIR}/metadata\"\n",
        "TRAINING_DIR = f\"{BASE}/training\"\n",
        "MODELS_DIR = f\"{BASE}/models\"\n",
        "\n",
        "os.makedirs(EXPERIMENTS_DIR, exist_ok=True)\n",
        "os.makedirs(METADATA_DIR, exist_ok=True)\n",
        "os.makedirs(TRAINING_DIR, exist_ok=True)\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "EXPERIMENTS_DIR, METADATA_DIR, TRAINING_DIR, MODELS_DIR\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRMqxlXztawY",
        "outputId": "0f8ceaca-c09e-4852-8fa3-9acc9a478df3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/ecopackai/ml/experiments',\n",
              " '/content/ecopackai/ml/experiments/metadata',\n",
              " '/content/ecopackai/ml/training',\n",
              " '/content/ecopackai/ml/models')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_experiment_id(model, target, dataset_version=\"v1\"):\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    return f\"{model}__{target}__{dataset_version}__{ts}\"\n"
      ],
      "metadata": {
        "id": "iR_jf9fJtkMo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def create_metadata(exp_id, model_name, target, dataset_version,\n",
        "                    feature_version, params, metrics):\n",
        "    return {\n",
        "        \"experiment_id\": exp_id,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"dataset_version\": dataset_version,\n",
        "        \"feature_set_version\": feature_version,\n",
        "        \"model_name\": model_name,\n",
        "        \"model_parameters\": params,\n",
        "        \"target_variable\": target,\n",
        "        \"evaluation_metrics\": metrics\n",
        "    }\n"
      ],
      "metadata": {
        "id": "4po4ODABttNS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VERSION_LOG = \"/content/ecopackai/docs/model_version_history.md\"\n"
      ],
      "metadata": {
        "id": "wrO483vSumeU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(os.path.dirname(VERSION_LOG), exist_ok=True)\n",
        "if not os.path.exists(VERSION_LOG):\n",
        "    with open(VERSION_LOG, \"w\") as f:\n",
        "        f.write(\"# Model Version History\\n\\n\")"
      ],
      "metadata": {
        "id": "Sj4IdMhguoXL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "aQgp0yQtvfe8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_log(model, model_name, X_train, y_train, X_test, y_test,\n",
        "                  target, dataset_version=\"v1\", feature_version=\"v1\",\n",
        "                  model_version=1):\n",
        "\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    # Metrics\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    r2 = r2_score(y_test, preds)\n",
        "\n",
        "    metrics = {\n",
        "        \"MAE\": round(mae, 3),\n",
        "        \"RMSE\": round(rmse, 3),\n",
        "        \"R2\": round(r2, 3)\n",
        "    }\n",
        "\n",
        "    # Experiment ID\n",
        "    exp_id = generate_experiment_id(model_name, target, dataset_version)\n",
        "\n",
        "    # Save model\n",
        "    model_filename = f\"{model_name}_{target}_v{model_version}.pkl\"\n",
        "    model_path = f\"{MODELS_DIR}/{model_filename}\"\n",
        "    joblib.dump(model, model_path)\n",
        "\n",
        "    # Save metadata\n",
        "    metadata = create_metadata(\n",
        "        exp_id, model_name, target, dataset_version,\n",
        "        feature_version, model.get_params(), metrics\n",
        "    )\n",
        "\n",
        "    meta_path = f\"{METADATA_DIR}/{exp_id}.json\"\n",
        "    with open(meta_path, \"w\") as f:\n",
        "        json.dump(metadata, f, indent=2)\n",
        "\n",
        "    # Update version history\n",
        "    with open(VERSION_LOG, \"a\") as f:\n",
        "        f.write(f\"- {model_filename} | target={target} | metrics={metrics}\\n\")\n",
        "\n",
        "    return model_path, meta_path, metrics\n"
      ],
      "metadata": {
        "id": "2WDLreblvhkA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "MQ1HG_Wwvjvm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "X = pd.read_csv(\"/content/ecopackai/ml/models/X_raw.csv\")\n",
        "y = pd.read_csv(\"/content/ecopackai/ml/models/y_raw.csv\")\n",
        "\n",
        "# Example: cost target (adjust if needed)\n",
        "target_col = y.columns[0]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y[target_col], test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "bh8K_Exovlst"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Identify categorical and numerical columns in X\n",
        "categorical_features_X = X_train.select_dtypes(include=['object']).columns\n",
        "numerical_features_X = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Create a pipeline for numerical features (imputation)\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "# Create a column transformer for one-hot encoding categorical features and imputing numerical features\n",
        "preprocessor_X = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features_X),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_X)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply preprocessing to X_train and X_test\n",
        "X_train_processed = preprocessor_X.fit_transform(X_train)\n",
        "X_test_processed = preprocessor_X.transform(X_test)\n",
        "\n",
        "# For y_train and y_test (recommended_material is categorical string)\n",
        "# LinearRegression is not typically suitable for categorical targets.\n",
        "# However, to make the code runnable, we will LabelEncode y.\n",
        "# If the goal is classification, a classification model should be used instead.\n",
        "label_encoder_y = LabelEncoder()\n",
        "y_train_processed = label_encoder_y.fit_transform(y_train)\n",
        "y_test_processed = label_encoder_y.transform(y_test)\n",
        "\n",
        "lr = LinearRegression()\n",
        "\n",
        "model_path, meta_path, metrics = train_and_log(\n",
        "    model=lr,\n",
        "    model_name=\"LinearRegression\",\n",
        "    X_train=X_train_processed,\n",
        "    y_train=y_train_processed,\n",
        "    X_test=X_test_processed,\n",
        "    y_test=y_test_processed,\n",
        "    target=target_col,\n",
        "    model_version=1\n",
        ")\n",
        "\n",
        "model_path, meta_path, metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keJ-p5S0wFHg",
        "outputId": "0ac6cb4f-6087-46df-bbf2-9d60757fab02"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/ecopackai/ml/models/LinearRegression_recommended_material_v1.pkl',\n",
              " '/content/ecopackai/ml/experiments/metadata/LinearRegression__recommended_material__v1__20251223_102943.json',\n",
              " {'MAE': 0.0, 'RMSE': np.float64(0.0), 'R2': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(METADATA_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmO36q8KwiFO",
        "outputId": "ab5cb8cc-18c6-4dde-ea9d-be4c8a64b413"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LinearRegression__recommended_material__v1__20251223_102943.json']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(MODELS_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwR2CtoVwkGl",
        "outputId": "1cf05089-4a9b-46df-edf2-99c61fe8028c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LinearRegression_recommended_material_v1.pkl', 'y_raw.csv', 'X_raw.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "framework_doc = \"\"\"\n",
        "# Training & Experiment Framework\n",
        "\n",
        "All experiments follow a standardized workflow:\n",
        "1. Load dataset & features\n",
        "2. Train model\n",
        "3. Evaluate MAE, RMSE, R2\n",
        "4. Save model artifact\n",
        "5. Log metadata per run\n",
        "6. Update model version history\n",
        "\n",
        "This ensures reproducibility and comparability.\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{TRAINING_DIR}/training_workflow.md\", \"w\") as f:\n",
        "    f.write(framework_doc)\n"
      ],
      "metadata": {
        "id": "0Iiw-wCpwl9M"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}